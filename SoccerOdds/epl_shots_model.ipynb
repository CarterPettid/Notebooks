{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPL Player Props Betting Model: Shots & Shots on Target\n",
    "\n",
    "A probabilistic model for finding edges in EPL player shot markets.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements:\n",
    "1. **Two-stage minutes prediction** (start probability + conditional minutes)\n",
    "2. **Hierarchical Negative Binomial model** for shots/SOT with player & opponent effects\n",
    "3. **De-vigging** bookmaker odds to extract fair probabilities\n",
    "4. **Walk-forward backtesting** with CLV as primary edge metric\n",
    "5. **Weekly candidate generation** with Kelly-based stake sizing\n",
    "\n",
    "### Assumptions & Limitations\n",
    "\n",
    "- No guaranteed profit is claimed\n",
    "- Edges must be validated via CLV and calibration over large sample sizes\n",
    "- Model assumes pre-match betting only (no in-play)\n",
    "- Requires 1000+ bets for statistical significance\n",
    "- Follow local gambling laws and sportsbook terms of service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical modeling\n",
    "from scipy import stats\n",
    "from scipy.optimize import brentq, minimize\n",
    "from scipy.special import gammaln\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.count_model import NegativeBinomialP\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import brier_score_loss, log_loss, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Dependencies loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    # Data settings\n",
    "    'seasons': ['2019-20', '2020-21', '2021-22', '2022-23', '2023-24'],\n",
    "    'min_minutes_for_model': 10,  # Minimum minutes to include in training\n",
    "    \n",
    "    # Feature engineering\n",
    "    'ewma_spans': [3, 10, 20],  # Short, medium, long-term EWMA windows\n",
    "    'rolling_windows': [5, 10],  # Rolling average windows\n",
    "    \n",
    "    # Minutes model\n",
    "    'congestion_days_threshold': 4,  # Days between matches for rotation risk\n",
    "    \n",
    "    # Shot model\n",
    "    'min_player_appearances': 10,  # Minimum games for player effect\n",
    "    \n",
    "    # Betting rules\n",
    "    'min_ev_threshold': 0.03,  # Minimum 3% EV to bet\n",
    "    'kelly_fraction': 0.25,   # Quarter Kelly\n",
    "    'max_bet_fraction': 0.02,  # Max 2% of bankroll per bet\n",
    "    'max_bets_per_match': 3,   # Limit correlated bets\n",
    "    \n",
    "    # Backtesting\n",
    "    'train_seasons': 3,  # Minimum seasons for training\n",
    "    'test_window_weeks': 4,  # Test on 4 weeks before retraining\n",
    "}\n",
    "\n",
    "print(\"Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Schema\n",
    "\n",
    "This section handles data ingestion. For real usage, connect to FBref via `soccerdata`.\n",
    "Here we generate realistic synthetic data matching the expected schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_epl_data(n_seasons=5, n_teams=20, players_per_team=25):\n",
    "    \"\"\"\n",
    "    Generate realistic synthetic EPL player-match data for model development.\n",
    "    Replace with actual FBref data loading for production use.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate teams\n",
    "    teams = [f'Team_{i}' for i in range(n_teams)]\n",
    "    \n",
    "    # Generate players with inherent shot tendencies\n",
    "    players = []\n",
    "    player_attributes = {}\n",
    "    \n",
    "    positions = ['GK', 'CB', 'FB', 'DM', 'CM', 'AM', 'W', 'ST']\n",
    "    position_shot_rates = {'GK': 0.01, 'CB': 0.3, 'FB': 0.5, 'DM': 0.8, \n",
    "                           'CM': 1.2, 'AM': 2.0, 'W': 2.2, 'ST': 3.5}\n",
    "    position_start_prob = {'GK': 0.95, 'CB': 0.85, 'FB': 0.80, 'DM': 0.75,\n",
    "                           'CM': 0.70, 'AM': 0.65, 'W': 0.60, 'ST': 0.70}\n",
    "    \n",
    "    player_id = 0\n",
    "    for team in teams:\n",
    "        for _ in range(players_per_team):\n",
    "            pos = np.random.choice(positions, p=[0.08, 0.16, 0.16, 0.12, 0.16, 0.12, 0.12, 0.08])\n",
    "            base_rate = position_shot_rates[pos]\n",
    "            # Add player-specific variation\n",
    "            player_shot_rate = base_rate * np.random.lognormal(0, 0.3)\n",
    "            player_start_base = position_start_prob[pos] * np.random.uniform(0.7, 1.1)\n",
    "            \n",
    "            player_attributes[player_id] = {\n",
    "                'team': team,\n",
    "                'position': pos,\n",
    "                'base_shot_rate': player_shot_rate,\n",
    "                'base_start_prob': min(0.95, player_start_base),\n",
    "                'sot_conversion': np.random.beta(3, 4)  # Shots on target / shots\n",
    "            }\n",
    "            players.append(player_id)\n",
    "            player_id += 1\n",
    "    \n",
    "    # Generate team attack/defense strengths\n",
    "    team_attack = {t: np.random.normal(1.0, 0.25) for t in teams}\n",
    "    team_defense = {t: np.random.normal(1.0, 0.25) for t in teams}\n",
    "    \n",
    "    # Generate match-level data\n",
    "    records = []\n",
    "    match_id = 0\n",
    "    \n",
    "    for season_idx in range(n_seasons):\n",
    "        season = CONFIG['seasons'][season_idx] if season_idx < len(CONFIG['seasons']) else f'Season_{season_idx}'\n",
    "        \n",
    "        # 38 matchweeks per season\n",
    "        for matchweek in range(1, 39):\n",
    "            match_date = pd.Timestamp(f'202{season_idx}-08-01') + pd.Timedelta(weeks=matchweek-1)\n",
    "            \n",
    "            # Generate 10 matches per matchweek\n",
    "            shuffled_teams = np.random.permutation(teams)\n",
    "            for i in range(0, n_teams, 2):\n",
    "                home_team = shuffled_teams[i]\n",
    "                away_team = shuffled_teams[i+1]\n",
    "                \n",
    "                # Match context\n",
    "                home_advantage = 1.15\n",
    "                match_tempo = np.random.uniform(0.8, 1.2)  # Some matches more open\n",
    "                \n",
    "                # Days since last match (congestion)\n",
    "                days_rest_home = np.random.choice([3, 4, 5, 6, 7, 8], p=[0.1, 0.2, 0.15, 0.15, 0.3, 0.1])\n",
    "                days_rest_away = np.random.choice([3, 4, 5, 6, 7, 8], p=[0.1, 0.2, 0.15, 0.15, 0.3, 0.1])\n",
    "                \n",
    "                # Generate player records for both teams\n",
    "                for is_home, team, opp_team, days_rest in [(True, home_team, away_team, days_rest_home),\n",
    "                                                            (False, away_team, home_team, days_rest_away)]:\n",
    "                    team_players = [p for p in players if player_attributes[p]['team'] == team]\n",
    "                    \n",
    "                    for player in team_players:\n",
    "                        attrs = player_attributes[player]\n",
    "                        \n",
    "                        # Determine if player starts (rotation based on congestion)\n",
    "                        congestion_factor = 0.9 if days_rest < CONFIG['congestion_days_threshold'] else 1.0\n",
    "                        start_prob = attrs['base_start_prob'] * congestion_factor\n",
    "                        started = np.random.random() < start_prob\n",
    "                        \n",
    "                        # Minutes played\n",
    "                        if started:\n",
    "                            # Starters: mostly full match, some subbed off\n",
    "                            if np.random.random() < 0.75:\n",
    "                                minutes = np.random.randint(85, 91)\n",
    "                            else:\n",
    "                                minutes = np.random.randint(45, 85)\n",
    "                        else:\n",
    "                            # Subs: many don't play, some get short appearances\n",
    "                            if np.random.random() < 0.6:\n",
    "                                minutes = 0\n",
    "                            else:\n",
    "                                minutes = np.random.randint(1, 45)\n",
    "                        \n",
    "                        if minutes == 0:\n",
    "                            shots, sot, goals, xg = 0, 0, 0, 0.0\n",
    "                        else:\n",
    "                            # Shot generation based on rate, minutes, context\n",
    "                            rate_per90 = attrs['base_shot_rate']\n",
    "                            rate_per90 *= team_attack[team]  # Team attacking strength\n",
    "                            rate_per90 *= (2 - team_defense[opp_team])  # Opponent defensive weakness\n",
    "                            rate_per90 *= match_tempo\n",
    "                            if is_home:\n",
    "                                rate_per90 *= home_advantage\n",
    "                            \n",
    "                            # Draw from Negative Binomial (overdispersed)\n",
    "                            expected_shots = rate_per90 * (minutes / 90)\n",
    "                            dispersion = 2.0  # Overdispersion parameter\n",
    "                            if expected_shots > 0:\n",
    "                                r = expected_shots / (dispersion - 1) if dispersion > 1 else expected_shots\n",
    "                                p = 1 / dispersion\n",
    "                                shots = stats.nbinom.rvs(n=max(0.1, r), p=min(0.99, max(0.01, p)))\n",
    "                            else:\n",
    "                                shots = 0\n",
    "                            \n",
    "                            # Shots on target\n",
    "                            sot = np.random.binomial(shots, attrs['sot_conversion'])\n",
    "                            \n",
    "                            # Goals (roughly 10% of shots)\n",
    "                            goals = np.random.binomial(sot, 0.35)\n",
    "                            \n",
    "                            # xG (correlated with shots but not perfectly)\n",
    "                            xg = shots * np.random.uniform(0.08, 0.15) if shots > 0 else 0\n",
    "                        \n",
    "                        records.append({\n",
    "                            'match_id': match_id,\n",
    "                            'season': season,\n",
    "                            'matchweek': matchweek,\n",
    "                            'date': match_date,\n",
    "                            'player_id': player,\n",
    "                            'player_name': f'Player_{player}',\n",
    "                            'team': team,\n",
    "                            'opponent': opp_team,\n",
    "                            'is_home': is_home,\n",
    "                            'position': attrs['position'],\n",
    "                            'started': started,\n",
    "                            'minutes': minutes,\n",
    "                            'shots': shots,\n",
    "                            'shots_on_target': sot,\n",
    "                            'goals': goals,\n",
    "                            'xg': round(xg, 3),\n",
    "                            'days_rest': days_rest,\n",
    "                        })\n",
    "                \n",
    "                match_id += 1\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(['date', 'match_id', 'player_id']).reset_index(drop=True)\n",
    "    \n",
    "    return df, player_attributes, team_attack, team_defense\n",
    "\n",
    "# Generate data\n",
    "print(\"Generating synthetic EPL data...\")\n",
    "df_raw, player_attrs, team_atk, team_def = generate_synthetic_epl_data()\n",
    "print(f\"Generated {len(df_raw):,} player-match records\")\n",
    "print(f\"Date range: {df_raw['date'].min()} to {df_raw['date'].max()}\")\n",
    "print(f\"Unique players: {df_raw['player_id'].nunique()}\")\n",
    "print(f\"Unique matches: {df_raw['match_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data schema documentation\n",
    "print(\"\\n=== DATA SCHEMA ===\")\n",
    "print(df_raw.dtypes)\n",
    "print(\"\\n=== SAMPLE DATA ===\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data loading function (uncomment to use with actual FBref data)\n",
    "\"\"\"\n",
    "def load_fbref_data(seasons):\n",
    "    import soccerdata as sd\n",
    "    \n",
    "    fbref = sd.FBref('ENG-Premier League', seasons)\n",
    "    \n",
    "    # Load player match stats\n",
    "    shooting = fbref.read_player_match_stats(stat_type='shooting')\n",
    "    summary = fbref.read_player_match_stats(stat_type='summary')\n",
    "    \n",
    "    # Merge and clean\n",
    "    df = shooting.merge(summary[['minutes', 'started']], \n",
    "                        left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # Reset index and clean column names\n",
    "    df = df.reset_index()\n",
    "    df.columns = [c.lower().replace(' ', '_') for c in df.columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# df_raw = load_fbref_data(['2324', '2223', '2122', '2021', '1920'])\n",
    "\"\"\"\n",
    "print(\"FBref loading function defined (commented out - using synthetic data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create all features for minutes and shot models.\n",
    "    Uses only backward-looking information to prevent leakage.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['player_id', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # === Player-level rolling features ===\n",
    "    for span in CONFIG['ewma_spans']:\n",
    "        # EWMA for shot rates (shifted to prevent leakage)\n",
    "        df[f'shots_ewma_{span}'] = df.groupby('player_id')['shots'].transform(\n",
    "            lambda x: x.shift(1).ewm(span=span, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'sot_ewma_{span}'] = df.groupby('player_id')['shots_on_target'].transform(\n",
    "            lambda x: x.shift(1).ewm(span=span, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'minutes_ewma_{span}'] = df.groupby('player_id')['minutes'].transform(\n",
    "            lambda x: x.shift(1).ewm(span=span, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'xg_ewma_{span}'] = df.groupby('player_id')['xg'].transform(\n",
    "            lambda x: x.shift(1).ewm(span=span, min_periods=1).mean()\n",
    "        )\n",
    "    \n",
    "    # Rolling start probability\n",
    "    df['starts_rolling_5'] = df.groupby('player_id')['started'].transform(\n",
    "        lambda x: x.shift(1).rolling(5, min_periods=1).mean()\n",
    "    )\n",
    "    df['starts_rolling_10'] = df.groupby('player_id')['started'].transform(\n",
    "        lambda x: x.shift(1).rolling(10, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Per-90 rates (using EWMA minutes to avoid division by current minutes)\n",
    "    df['shots_per90_ewma'] = np.where(\n",
    "        df['minutes_ewma_10'] > 0,\n",
    "        df['shots_ewma_10'] / (df['minutes_ewma_10'] / 90),\n",
    "        0\n",
    "    )\n",
    "    df['sot_per90_ewma'] = np.where(\n",
    "        df['minutes_ewma_10'] > 0,\n",
    "        df['sot_ewma_10'] / (df['minutes_ewma_10'] / 90),\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # === Team-level features ===\n",
    "    # Team's rolling shot volume (proxy for attacking style)\n",
    "    team_shots = df.groupby(['team', 'date'])['shots'].sum().reset_index()\n",
    "    team_shots = team_shots.sort_values(['team', 'date'])\n",
    "    team_shots['team_shots_ewma'] = team_shots.groupby('team')['shots'].transform(\n",
    "        lambda x: x.shift(1).ewm(span=10, min_periods=1).mean()\n",
    "    )\n",
    "    team_shots_dict = team_shots.set_index(['team', 'date'])['team_shots_ewma'].to_dict()\n",
    "    df['team_shots_ewma'] = df.apply(\n",
    "        lambda r: team_shots_dict.get((r['team'], r['date']), np.nan), axis=1\n",
    "    )\n",
    "    \n",
    "    # === Opponent-level features ===\n",
    "    # Opponent's shots conceded (defensive quality)\n",
    "    opp_shots = df.groupby(['opponent', 'date'])['shots'].sum().reset_index()\n",
    "    opp_shots = opp_shots.sort_values(['opponent', 'date'])\n",
    "    opp_shots['opp_shots_conceded_ewma'] = opp_shots.groupby('opponent')['shots'].transform(\n",
    "        lambda x: x.shift(1).ewm(span=10, min_periods=1).mean()\n",
    "    )\n",
    "    opp_shots_dict = opp_shots.set_index(['opponent', 'date'])['opp_shots_conceded_ewma'].to_dict()\n",
    "    df['opp_shots_conceded_ewma'] = df.apply(\n",
    "        lambda r: opp_shots_dict.get((r['opponent'], r['date']), np.nan), axis=1\n",
    "    )\n",
    "    \n",
    "    # === Match context features ===\n",
    "    df['is_home_int'] = df['is_home'].astype(int)\n",
    "    df['congestion'] = (df['days_rest'] < CONFIG['congestion_days_threshold']).astype(int)\n",
    "    \n",
    "    # Position encoding\n",
    "    position_map = {'GK': 0, 'CB': 1, 'FB': 2, 'DM': 3, 'CM': 4, 'AM': 5, 'W': 6, 'ST': 7}\n",
    "    df['position_code'] = df['position'].map(position_map)\n",
    "    df['is_attacker'] = df['position'].isin(['AM', 'W', 'ST']).astype(int)\n",
    "    \n",
    "    # Player appearance count (for filtering)\n",
    "    df['player_game_num'] = df.groupby('player_id').cumcount() + 1\n",
    "    \n",
    "    # Fill NaN with position/league medians where appropriate\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Creating features...\")\n",
    "df = create_features(df_raw)\n",
    "print(f\"Features created. Shape: {df.shape}\")\n",
    "print(f\"\\nNew columns: {[c for c in df.columns if c not in df_raw.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shot distribution analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "\n",
    "# Filter to players with meaningful minutes\n",
    "df_played = df[df['minutes'] >= CONFIG['min_minutes_for_model']]\n",
    "\n",
    "# Shot distribution (all players who played)\n",
    "axes[0, 0].hist(df_played['shots'], bins=range(0, 12), edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Shots')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title(f'Shot Distribution (n={len(df_played):,})')\n",
    "axes[0, 0].axvline(df_played['shots'].mean(), color='red', linestyle='--', label=f'Mean: {df_played[\"shots\"].mean():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# SOT distribution\n",
    "axes[0, 1].hist(df_played['shots_on_target'], bins=range(0, 8), edgecolor='black', alpha=0.7, color='green')\n",
    "axes[0, 1].set_xlabel('Shots on Target')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title(f'SOT Distribution')\n",
    "axes[0, 1].axvline(df_played['shots_on_target'].mean(), color='red', linestyle='--', label=f'Mean: {df_played[\"shots_on_target\"].mean():.2f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Minutes distribution (bimodal check)\n",
    "axes[0, 2].hist(df['minutes'], bins=range(0, 95, 5), edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0, 2].set_xlabel('Minutes')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "axes[0, 2].set_title('Minutes Distribution (Bimodal)')\n",
    "\n",
    "# Shots by position\n",
    "position_order = ['GK', 'CB', 'FB', 'DM', 'CM', 'AM', 'W', 'ST']\n",
    "shots_by_pos = df_played.groupby('position')['shots'].mean().reindex(position_order)\n",
    "axes[1, 0].bar(shots_by_pos.index, shots_by_pos.values, color='steelblue', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Position')\n",
    "axes[1, 0].set_ylabel('Mean Shots')\n",
    "axes[1, 0].set_title('Shots by Position')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Variance vs Mean (overdispersion check)\n",
    "player_stats = df_played.groupby('player_id').agg({'shots': ['mean', 'var']}).dropna()\n",
    "player_stats.columns = ['mean', 'var']\n",
    "player_stats = player_stats[player_stats['mean'] > 0]\n",
    "axes[1, 1].scatter(player_stats['mean'], player_stats['var'], alpha=0.3)\n",
    "max_val = max(player_stats['mean'].max(), player_stats['var'].max())\n",
    "axes[1, 1].plot([0, max_val], [0, max_val], 'r--', label='Var = Mean (Poisson)')\n",
    "axes[1, 1].set_xlabel('Mean Shots')\n",
    "axes[1, 1].set_ylabel('Variance')\n",
    "axes[1, 1].set_title('Overdispersion Check')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "# Home vs Away\n",
    "home_away = df_played.groupby('is_home')['shots'].mean()\n",
    "axes[1, 2].bar(['Away', 'Home'], home_away.values, color=['coral', 'seagreen'], edgecolor='black')\n",
    "axes[1, 2].set_ylabel('Mean Shots')\n",
    "axes[1, 2].set_title('Home vs Away Shots')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_shots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOverdispersion ratio (var/mean): {df_played['shots'].var() / df_played['shots'].mean():.2f}\")\n",
    "print(\"Values > 1 indicate overdispersion, supporting Negative Binomial over Poisson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Minutes Prediction Model (Two-Stage)\n",
    "\n",
    "Critical for accurate shot predictions: we need to model minutes uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinutesModel:\n",
    "    \"\"\"\n",
    "    Two-stage minutes prediction:\n",
    "    1. P(start) - Classification\n",
    "    2. Minutes | start vs Minutes | sub - Conditional distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.start_model = GradientBoostingClassifier(\n",
    "            n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42\n",
    "        )\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Distribution parameters (fit from data)\n",
    "        self.starter_mu = 82\n",
    "        self.starter_sigma = 12\n",
    "        self.sub_mu = 15\n",
    "        self.sub_sigma = 12\n",
    "        \n",
    "        self.feature_cols = [\n",
    "            'starts_rolling_5', 'starts_rolling_10',\n",
    "            'minutes_ewma_3', 'minutes_ewma_10',\n",
    "            'congestion', 'position_code', 'is_attacker'\n",
    "        ]\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \"\"\"Fit start probability model and distribution parameters.\"\"\"\n",
    "        # Filter to valid training data\n",
    "        train_df = df[df['player_game_num'] > 3].copy()  # Need history\n",
    "        \n",
    "        X = train_df[self.feature_cols].values\n",
    "        y = train_df['started'].values\n",
    "        \n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.start_model.fit(X_scaled, y)\n",
    "        \n",
    "        # Fit conditional distributions from data\n",
    "        starters = train_df[train_df['started'] == True]\n",
    "        subs = train_df[(train_df['started'] == False) & (train_df['minutes'] > 0)]\n",
    "        \n",
    "        self.starter_mu = starters['minutes'].mean()\n",
    "        self.starter_sigma = starters['minutes'].std()\n",
    "        self.sub_mu = subs['minutes'].mean() if len(subs) > 0 else 15\n",
    "        self.sub_sigma = subs['minutes'].std() if len(subs) > 0 else 10\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_start_prob(self, df):\n",
    "        \"\"\"Predict probability of starting.\"\"\"\n",
    "        X = df[self.feature_cols].values\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.start_model.predict_proba(X_scaled)[:, 1]\n",
    "    \n",
    "    def sample_minutes(self, start_probs, n_samples=1000):\n",
    "        \"\"\"\n",
    "        Sample from minutes distribution given start probabilities.\n",
    "        Returns array of shape (n_players, n_samples).\n",
    "        \"\"\"\n",
    "        n_players = len(start_probs)\n",
    "        samples = np.zeros((n_players, n_samples))\n",
    "        \n",
    "        for i, p_start in enumerate(start_probs):\n",
    "            starts = np.random.random(n_samples) < p_start\n",
    "            \n",
    "            # Sample minutes conditional on start/sub\n",
    "            starter_mins = np.clip(\n",
    "                np.random.normal(self.starter_mu, self.starter_sigma, n_samples),\n",
    "                45, 90\n",
    "            )\n",
    "            sub_mins = np.clip(\n",
    "                np.random.normal(self.sub_mu, self.sub_sigma, n_samples),\n",
    "                0, 45\n",
    "            )\n",
    "            \n",
    "            # Also model probability of not playing at all (if sub)\n",
    "            no_play = np.random.random(n_samples) < 0.5  # 50% of subs don't play\n",
    "            sub_mins = np.where(no_play, 0, sub_mins)\n",
    "            \n",
    "            samples[i] = np.where(starts, starter_mins, sub_mins)\n",
    "        \n",
    "        return samples\n",
    "\n",
    "# Train minutes model\n",
    "print(\"Training minutes model...\")\n",
    "minutes_model = MinutesModel()\n",
    "minutes_model.fit(df)\n",
    "\n",
    "# Evaluate on held-out data\n",
    "test_df = df[df['season'] == CONFIG['seasons'][-1]].copy()\n",
    "test_df = test_df[test_df['player_game_num'] > 3]\n",
    "\n",
    "start_probs = minutes_model.predict_start_prob(test_df)\n",
    "start_auc = roc_auc_score(test_df['started'], start_probs)\n",
    "start_brier = brier_score_loss(test_df['started'], start_probs)\n",
    "\n",
    "print(f\"\\nStart Probability Model Performance:\")\n",
    "print(f\"  AUC-ROC: {start_auc:.3f}\")\n",
    "print(f\"  Brier Score: {start_brier:.3f}\")\n",
    "print(f\"  Starter params: μ={minutes_model.starter_mu:.1f}, σ={minutes_model.starter_sigma:.1f}\")\n",
    "print(f\"  Sub params: μ={minutes_model.sub_mu:.1f}, σ={minutes_model.sub_sigma:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize minutes model\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Start probability calibration\n",
    "prob_true, prob_pred = calibration_curve(test_df['started'], start_probs, n_bins=10)\n",
    "axes[0].plot(prob_pred, prob_true, 's-', label='Model')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', label='Perfect')\n",
    "axes[0].set_xlabel('Predicted P(Start)')\n",
    "axes[0].set_ylabel('Actual Start Rate')\n",
    "axes[0].set_title('Start Probability Calibration')\n",
    "axes[0].legend()\n",
    "\n",
    "# Sample minutes distribution for a typical starter\n",
    "sample_mins = minutes_model.sample_minutes(np.array([0.8]), n_samples=5000)[0]\n",
    "axes[1].hist(sample_mins, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(sample_mins.mean(), color='red', linestyle='--', label=f'Mean: {sample_mins.mean():.1f}')\n",
    "axes[1].set_xlabel('Minutes')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Minutes Distribution (P(start)=0.8)')\n",
    "axes[1].legend()\n",
    "\n",
    "# Sample minutes distribution for a typical sub\n",
    "sample_mins_sub = minutes_model.sample_minutes(np.array([0.3]), n_samples=5000)[0]\n",
    "axes[2].hist(sample_mins_sub, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[2].axvline(sample_mins_sub.mean(), color='red', linestyle='--', label=f'Mean: {sample_mins_sub.mean():.1f}')\n",
    "axes[2].set_xlabel('Minutes')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Minutes Distribution (P(start)=0.3)')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('minutes_model.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Shot Distribution Models (Hierarchical Negative Binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalShotModel:\n",
    "    \"\"\"\n",
    "    Negative Binomial model for shots with player and team effects.\n",
    "    Uses statsmodels for frequentist estimation with random effects approximation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target='shots'):\n",
    "        self.target = target\n",
    "        self.model = None\n",
    "        self.player_effects = {}\n",
    "        self.team_effects = {}\n",
    "        self.opponent_effects = {}\n",
    "        self.dispersion = 1.0\n",
    "        \n",
    "        self.feature_cols = [\n",
    "            'is_home_int', 'position_code', 'is_attacker',\n",
    "            'shots_per90_ewma', 'team_shots_ewma', 'opp_shots_conceded_ewma'\n",
    "        ]\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \"\"\"Fit Negative Binomial regression with exposure (minutes).\"\"\"\n",
    "        # Filter training data\n",
    "        train_df = df[\n",
    "            (df['minutes'] >= CONFIG['min_minutes_for_model']) &\n",
    "            (df['player_game_num'] >= 5)\n",
    "        ].copy()\n",
    "        \n",
    "        # Prepare features\n",
    "        X = train_df[self.feature_cols].copy()\n",
    "        X = sm.add_constant(X)\n",
    "        y = train_df[self.target].values\n",
    "        exposure = train_df['minutes'].values / 90  # Exposure in 90-minute units\n",
    "        \n",
    "        # Fit Negative Binomial\n",
    "        self.model = NegativeBinomialP(\n",
    "            y, X, exposure=exposure\n",
    "        ).fit(disp=False, maxiter=100)\n",
    "        \n",
    "        self.dispersion = self.model.params[-1] if hasattr(self.model, 'params') else 1.0\n",
    "        \n",
    "        # Compute player-level effects (residual-based approximation)\n",
    "        train_df['predicted_rate'] = self.model.predict(X) / exposure\n",
    "        train_df['residual'] = (train_df[self.target] / (train_df['minutes']/90 + 0.1)) - train_df['predicted_rate']\n",
    "        \n",
    "        # Shrink player effects toward zero\n",
    "        player_resid = train_df.groupby('player_id')['residual'].agg(['mean', 'count'])\n",
    "        # Shrinkage factor based on sample size\n",
    "        shrinkage = player_resid['count'] / (player_resid['count'] + 10)\n",
    "        self.player_effects = (player_resid['mean'] * shrinkage).to_dict()\n",
    "        \n",
    "        # Team effects\n",
    "        team_resid = train_df.groupby('team')['residual'].mean()\n",
    "        self.team_effects = (team_resid * 0.5).to_dict()  # Shrink team effects\n",
    "        \n",
    "        # Opponent effects\n",
    "        opp_resid = train_df.groupby('opponent')['residual'].mean()\n",
    "        self.opponent_effects = (opp_resid * 0.5).to_dict()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_rate(self, df):\n",
    "        \"\"\"Predict shot rate per 90 minutes.\"\"\"\n",
    "        X = df[self.feature_cols].copy()\n",
    "        X = sm.add_constant(X, has_constant='add')\n",
    "        \n",
    "        # Base prediction (rate per 90)\n",
    "        base_rate = self.model.predict(X)\n",
    "        \n",
    "        # Add random effects\n",
    "        player_adj = df['player_id'].map(self.player_effects).fillna(0)\n",
    "        team_adj = df['team'].map(self.team_effects).fillna(0)\n",
    "        opp_adj = df['opponent'].map(self.opponent_effects).fillna(0)\n",
    "        \n",
    "        adjusted_rate = base_rate + player_adj + team_adj + opp_adj\n",
    "        return np.maximum(adjusted_rate, 0.01)  # Floor at small positive value\n",
    "    \n",
    "    def predict_proba_over(self, df, line, minutes_samples):\n",
    "        \"\"\"\n",
    "        Predict P(shots > line) integrating over minutes uncertainty.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with features\n",
    "            line: Betting line (e.g., 1.5, 2.5)\n",
    "            minutes_samples: Array of shape (n_players, n_samples)\n",
    "        \n",
    "        Returns:\n",
    "            Array of P(over) for each player\n",
    "        \"\"\"\n",
    "        rate_per90 = self.predict_rate(df).values\n",
    "        n_players = len(df)\n",
    "        n_samples = minutes_samples.shape[1]\n",
    "        \n",
    "        # Get dispersion parameter\n",
    "        alpha = max(0.1, getattr(self, 'dispersion', 1.0))\n",
    "        \n",
    "        probs_over = np.zeros(n_players)\n",
    "        \n",
    "        for i in range(n_players):\n",
    "            # For each minutes sample, compute P(shots > line)\n",
    "            p_over_samples = []\n",
    "            \n",
    "            for mins in minutes_samples[i]:\n",
    "                if mins < 5:  # Very short appearance\n",
    "                    p_over_samples.append(0.0)\n",
    "                    continue\n",
    "                \n",
    "                mu = rate_per90[i] * (mins / 90)\n",
    "                \n",
    "                # Negative Binomial: parameterized by mean and dispersion\n",
    "                # scipy uses n, p parameterization: n = 1/alpha, p = 1/(1 + alpha*mu)\n",
    "                r = 1 / alpha\n",
    "                p = r / (r + mu)\n",
    "                \n",
    "                # P(X > line) = 1 - P(X <= floor(line))\n",
    "                p_over = 1 - stats.nbinom.cdf(int(line), n=r, p=p)\n",
    "                p_over_samples.append(p_over)\n",
    "            \n",
    "            probs_over[i] = np.mean(p_over_samples)\n",
    "        \n",
    "        return probs_over\n",
    "\n",
    "# Train shot models\n",
    "print(\"Training shot models...\")\n",
    "\n",
    "# Use earlier seasons for training\n",
    "train_seasons = CONFIG['seasons'][:-1]\n",
    "train_df = df[df['season'].isin(train_seasons)]\n",
    "\n",
    "shot_model = HierarchicalShotModel(target='shots')\n",
    "shot_model.fit(train_df)\n",
    "\n",
    "sot_model = HierarchicalShotModel(target='shots_on_target')\n",
    "sot_model.fit(train_df)\n",
    "\n",
    "print(f\"\\nShots model coefficients:\")\n",
    "print(shot_model.model.summary().tables[1])\n",
    "print(f\"\\nNumber of player effects: {len(shot_model.player_effects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate shot model predictions\n",
    "test_df = df[df['season'] == CONFIG['seasons'][-1]].copy()\n",
    "test_df = test_df[\n",
    "    (test_df['minutes'] >= CONFIG['min_minutes_for_model']) &\n",
    "    (test_df['player_game_num'] >= 5)\n",
    "]\n",
    "\n",
    "# Predict rates\n",
    "test_df['pred_shot_rate'] = shot_model.predict_rate(test_df)\n",
    "test_df['pred_shots'] = test_df['pred_shot_rate'] * (test_df['minutes'] / 90)\n",
    "\n",
    "# Calculate errors\n",
    "mae = np.abs(test_df['shots'] - test_df['pred_shots']).mean()\n",
    "rmse = np.sqrt(((test_df['shots'] - test_df['pred_shots'])**2).mean())\n",
    "\n",
    "print(f\"Shot Model Performance (using actual minutes):\")\n",
    "print(f\"  MAE: {mae:.3f}\")\n",
    "print(f\"  RMSE: {rmse:.3f}\")\n",
    "print(f\"  Mean actual shots: {test_df['shots'].mean():.3f}\")\n",
    "print(f\"  Mean predicted shots: {test_df['pred_shots'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Odds De-Vigging & Expected Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OddsProcessor:\n",
    "    \"\"\"Handle bookmaker odds: de-vigging, EV calculation, and Kelly sizing.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def american_to_decimal(american):\n",
    "        \"\"\"Convert American odds to decimal.\"\"\"\n",
    "        if american > 0:\n",
    "            return (american / 100) + 1\n",
    "        else:\n",
    "            return (100 / abs(american)) + 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def decimal_to_implied(decimal_odds):\n",
    "        \"\"\"Convert decimal odds to implied probability.\"\"\"\n",
    "        return 1 / decimal_odds\n",
    "    \n",
    "    @staticmethod\n",
    "    def devig_multiplicative(odds_over, odds_under):\n",
    "        \"\"\"\n",
    "        Multiplicative (proportional) de-vig method.\n",
    "        Distributes vig proportionally.\n",
    "        \"\"\"\n",
    "        imp_over = 1 / odds_over\n",
    "        imp_under = 1 / odds_under\n",
    "        total = imp_over + imp_under\n",
    "        \n",
    "        return {\n",
    "            'fair_prob_over': imp_over / total,\n",
    "            'fair_prob_under': imp_under / total,\n",
    "            'vig': (total - 1) * 100\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def devig_power(odds_over, odds_under):\n",
    "        \"\"\"\n",
    "        Power method de-vig - better for favorite/longshot bias.\n",
    "        Finds k such that implied_over^k + implied_under^k = 1\n",
    "        \"\"\"\n",
    "        imp_over = 1 / odds_over\n",
    "        imp_under = 1 / odds_under\n",
    "        \n",
    "        def objective(k):\n",
    "            return (imp_over ** k) + (imp_under ** k) - 1\n",
    "        \n",
    "        try:\n",
    "            k = brentq(objective, 0.1, 2.0)\n",
    "            fair_over = imp_over ** k\n",
    "            fair_under = imp_under ** k\n",
    "        except:\n",
    "            # Fall back to multiplicative if power method fails\n",
    "            total = imp_over + imp_under\n",
    "            fair_over = imp_over / total\n",
    "            fair_under = imp_under / total\n",
    "            k = 1.0\n",
    "        \n",
    "        return {\n",
    "            'fair_prob_over': fair_over,\n",
    "            'fair_prob_under': fair_under,\n",
    "            'k': k,\n",
    "            'vig': (imp_over + imp_under - 1) * 100\n",
    "        }\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_ev(model_prob, decimal_odds):\n",
    "        \"\"\"\n",
    "        Calculate expected value of a bet.\n",
    "        EV = P(win) * (odds - 1) - P(lose)\n",
    "        \"\"\"\n",
    "        p_win = model_prob\n",
    "        p_lose = 1 - model_prob\n",
    "        ev = p_win * (decimal_odds - 1) - p_lose\n",
    "        return ev\n",
    "    \n",
    "    @staticmethod\n",
    "    def kelly_stake(model_prob, decimal_odds, fraction=0.25, max_stake=0.02):\n",
    "        \"\"\"\n",
    "        Calculate Kelly criterion stake.\n",
    "        \n",
    "        Args:\n",
    "            model_prob: Your estimated probability of winning\n",
    "            decimal_odds: Decimal odds offered\n",
    "            fraction: Kelly fraction (0.25 = quarter Kelly)\n",
    "            max_stake: Maximum stake as fraction of bankroll\n",
    "        \n",
    "        Returns:\n",
    "            Recommended stake as fraction of bankroll\n",
    "        \"\"\"\n",
    "        b = decimal_odds - 1  # Net odds\n",
    "        q = 1 - model_prob    # Probability of losing\n",
    "        \n",
    "        # Kelly formula: (bp - q) / b\n",
    "        full_kelly = (b * model_prob - q) / b\n",
    "        \n",
    "        # Apply fraction and cap\n",
    "        stake = max(0, full_kelly * fraction)\n",
    "        stake = min(stake, max_stake)\n",
    "        \n",
    "        return stake\n",
    "\n",
    "# Example: de-vig some odds\n",
    "print(\"De-vig Example:\")\n",
    "print(\"Book offers: Over 1.5 shots @ 1.80, Under 1.5 shots @ 2.00\")\n",
    "\n",
    "result_mult = OddsProcessor.devig_multiplicative(1.80, 2.00)\n",
    "result_power = OddsProcessor.devig_power(1.80, 2.00)\n",
    "\n",
    "print(f\"\\nMultiplicative method:\")\n",
    "print(f\"  Fair P(Over): {result_mult['fair_prob_over']:.3f}\")\n",
    "print(f\"  Fair P(Under): {result_mult['fair_prob_under']:.3f}\")\n",
    "print(f\"  Vig: {result_mult['vig']:.1f}%\")\n",
    "\n",
    "print(f\"\\nPower method:\")\n",
    "print(f\"  Fair P(Over): {result_power['fair_prob_over']:.3f}\")\n",
    "print(f\"  Fair P(Under): {result_power['fair_prob_under']:.3f}\")\n",
    "print(f\"  Vig: {result_power['vig']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_odds(df, shot_model, minutes_model):\n",
    "    \"\"\"\n",
    "    Generate synthetic bookmaker odds for backtesting.\n",
    "    In production, load real odds from CSV/API.\n",
    "    \"\"\"\n",
    "    np.random.seed(123)\n",
    "    \n",
    "    odds_records = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['position'] == 'GK':  # Skip goalkeepers\n",
    "            continue\n",
    "        \n",
    "        # Simulate \"true\" probability (with noise)\n",
    "        player_df = df[df.index == row.name]\n",
    "        start_prob = minutes_model.predict_start_prob(player_df)[0]\n",
    "        minutes_samples = minutes_model.sample_minutes(np.array([start_prob]), n_samples=500)\n",
    "        \n",
    "        # Get model probability for over 1.5 shots\n",
    "        true_prob_over = shot_model.predict_proba_over(player_df, line=1.5, minutes_samples=minutes_samples)[0]\n",
    "        \n",
    "        if true_prob_over < 0.05 or true_prob_over > 0.95:  # Skip extreme cases\n",
    "            continue\n",
    "        \n",
    "        # Simulate bookmaker's estimate (slightly different from true)\n",
    "        book_error = np.random.normal(0, 0.05)  # Book has some error\n",
    "        book_prob = np.clip(true_prob_over + book_error, 0.1, 0.9)\n",
    "        \n",
    "        # Add vig (5% total)\n",
    "        vig = 0.05\n",
    "        odds_over = 1 / (book_prob * (1 + vig/2))\n",
    "        odds_under = 1 / ((1 - book_prob) * (1 + vig/2))\n",
    "        \n",
    "        odds_records.append({\n",
    "            'match_id': row['match_id'],\n",
    "            'player_id': row['player_id'],\n",
    "            'date': row['date'],\n",
    "            'market': 'shots_over_1.5',\n",
    "            'line': 1.5,\n",
    "            'odds_over': round(odds_over, 2),\n",
    "            'odds_under': round(odds_under, 2),\n",
    "            'actual_shots': row['shots']\n",
    "        })\n",
    "        \n",
    "        # Also generate for 2.5 line\n",
    "        true_prob_over_25 = shot_model.predict_proba_over(player_df, line=2.5, minutes_samples=minutes_samples)[0]\n",
    "        if 0.05 < true_prob_over_25 < 0.95:\n",
    "            book_prob_25 = np.clip(true_prob_over_25 + np.random.normal(0, 0.05), 0.1, 0.9)\n",
    "            odds_over_25 = 1 / (book_prob_25 * (1 + vig/2))\n",
    "            odds_under_25 = 1 / ((1 - book_prob_25) * (1 + vig/2))\n",
    "            \n",
    "            odds_records.append({\n",
    "                'match_id': row['match_id'],\n",
    "                'player_id': row['player_id'],\n",
    "                'date': row['date'],\n",
    "                'market': 'shots_over_2.5',\n",
    "                'line': 2.5,\n",
    "                'odds_over': round(odds_over_25, 2),\n",
    "                'odds_under': round(odds_under_25, 2),\n",
    "                'actual_shots': row['shots']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(odds_records)\n",
    "\n",
    "print(\"Generating synthetic odds for backtesting...\")\n",
    "# Use test season data\n",
    "test_season_df = df[df['season'] == CONFIG['seasons'][-1]].copy()\n",
    "test_season_df = test_season_df[test_season_df['player_game_num'] >= 5]\n",
    "\n",
    "# Sample for speed\n",
    "sample_df = test_season_df.sample(n=min(2000, len(test_season_df)), random_state=42)\n",
    "odds_df = generate_synthetic_odds(sample_df, shot_model, minutes_model)\n",
    "\n",
    "print(f\"Generated {len(odds_df):,} odds records\")\n",
    "odds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Walk-Forward Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backtester:\n",
    "    \"\"\"\n",
    "    Walk-forward backtesting framework with CLV tracking.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.results = []\n",
    "    \n",
    "    def run_backtest(self, df, odds_df, minutes_model, shot_model):\n",
    "        \"\"\"\n",
    "        Execute walk-forward backtest.\n",
    "        \"\"\"\n",
    "        self.results = []\n",
    "        \n",
    "        # Merge odds with features\n",
    "        merged = odds_df.merge(\n",
    "            df[['match_id', 'player_id', 'date'] + shot_model.feature_cols + \n",
    "               minutes_model.feature_cols + ['position', 'started', 'minutes']],\n",
    "            on=['match_id', 'player_id', 'date'],\n",
    "            how='left'\n",
    "        ).dropna()\n",
    "        \n",
    "        for _, row in merged.iterrows():\n",
    "            # Get features for this player-match\n",
    "            player_df = merged[merged.index == row.name]\n",
    "            \n",
    "            # Predict start probability and sample minutes\n",
    "            start_prob = minutes_model.predict_start_prob(player_df)[0]\n",
    "            minutes_samples = minutes_model.sample_minutes(\n",
    "                np.array([start_prob]), n_samples=1000\n",
    "            )\n",
    "            \n",
    "            # Get model probability\n",
    "            model_prob_over = shot_model.predict_proba_over(\n",
    "                player_df, line=row['line'], minutes_samples=minutes_samples\n",
    "            )[0]\n",
    "            \n",
    "            # De-vig bookmaker odds\n",
    "            devigged = OddsProcessor.devig_power(row['odds_over'], row['odds_under'])\n",
    "            market_prob_over = devigged['fair_prob_over']\n",
    "            \n",
    "            # Calculate EV\n",
    "            ev_over = OddsProcessor.calculate_ev(model_prob_over, row['odds_over'])\n",
    "            ev_under = OddsProcessor.calculate_ev(1 - model_prob_over, row['odds_under'])\n",
    "            \n",
    "            # Determine if we bet\n",
    "            bet_side = None\n",
    "            bet_odds = None\n",
    "            bet_ev = 0\n",
    "            \n",
    "            if ev_over > self.config['min_ev_threshold']:\n",
    "                bet_side = 'over'\n",
    "                bet_odds = row['odds_over']\n",
    "                bet_ev = ev_over\n",
    "            elif ev_under > self.config['min_ev_threshold']:\n",
    "                bet_side = 'under'\n",
    "                bet_odds = row['odds_under']\n",
    "                bet_ev = ev_under\n",
    "            \n",
    "            if bet_side:\n",
    "                # Calculate stake\n",
    "                stake = OddsProcessor.kelly_stake(\n",
    "                    model_prob_over if bet_side == 'over' else (1 - model_prob_over),\n",
    "                    bet_odds,\n",
    "                    fraction=self.config['kelly_fraction'],\n",
    "                    max_stake=self.config['max_bet_fraction']\n",
    "                )\n",
    "                \n",
    "                # Determine outcome\n",
    "                actual_shots = row['actual_shots']\n",
    "                if bet_side == 'over':\n",
    "                    won = actual_shots > row['line']\n",
    "                else:\n",
    "                    won = actual_shots <= row['line']\n",
    "                \n",
    "                # Calculate profit\n",
    "                if won:\n",
    "                    profit = stake * (bet_odds - 1)\n",
    "                else:\n",
    "                    profit = -stake\n",
    "                \n",
    "                self.results.append({\n",
    "                    'date': row['date'],\n",
    "                    'player_id': row['player_id'],\n",
    "                    'market': row['market'],\n",
    "                    'line': row['line'],\n",
    "                    'bet_side': bet_side,\n",
    "                    'model_prob': model_prob_over if bet_side == 'over' else (1 - model_prob_over),\n",
    "                    'market_prob': market_prob_over if bet_side == 'over' else (1 - market_prob_over),\n",
    "                    'odds': bet_odds,\n",
    "                    'ev': bet_ev,\n",
    "                    'stake': stake,\n",
    "                    'won': won,\n",
    "                    'profit': profit,\n",
    "                    'actual_shots': actual_shots,\n",
    "                    # CLV proxy: edge vs market\n",
    "                    'clv': (model_prob_over - market_prob_over) if bet_side == 'over' else ((1-model_prob_over) - (1-market_prob_over))\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(self.results)\n",
    "    \n",
    "    def summarize_results(self, results_df):\n",
    "        \"\"\"Generate summary statistics.\"\"\"\n",
    "        if len(results_df) == 0:\n",
    "            return \"No bets placed\"\n",
    "        \n",
    "        total_staked = results_df['stake'].sum()\n",
    "        total_profit = results_df['profit'].sum()\n",
    "        n_bets = len(results_df)\n",
    "        n_wins = results_df['won'].sum()\n",
    "        \n",
    "        summary = {\n",
    "            'n_bets': n_bets,\n",
    "            'win_rate': n_wins / n_bets,\n",
    "            'total_staked': total_staked,\n",
    "            'total_profit': total_profit,\n",
    "            'roi': total_profit / total_staked if total_staked > 0 else 0,\n",
    "            'avg_ev': results_df['ev'].mean(),\n",
    "            'avg_clv': results_df['clv'].mean(),\n",
    "            'avg_odds': results_df['odds'].mean(),\n",
    "            'max_drawdown': self._calculate_drawdown(results_df)\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _calculate_drawdown(self, results_df):\n",
    "        \"\"\"Calculate maximum drawdown.\"\"\"\n",
    "        cumulative = results_df['profit'].cumsum()\n",
    "        running_max = cumulative.cummax()\n",
    "        drawdown = running_max - cumulative\n",
    "        return drawdown.max()\n",
    "\n",
    "# Run backtest\n",
    "print(\"Running backtest...\")\n",
    "backtester = Backtester(CONFIG)\n",
    "results_df = backtester.run_backtest(df, odds_df, minutes_model, shot_model)\n",
    "\n",
    "summary = backtester.summarize_results(results_df)\n",
    "print(f\"\\n=== BACKTEST RESULTS ===\")\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize backtest results\n",
    "if len(results_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Cumulative profit\n",
    "    results_df_sorted = results_df.sort_values('date')\n",
    "    cumulative_profit = results_df_sorted['profit'].cumsum()\n",
    "    axes[0, 0].plot(range(len(cumulative_profit)), cumulative_profit, linewidth=2)\n",
    "    axes[0, 0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0, 0].set_xlabel('Bet Number')\n",
    "    axes[0, 0].set_ylabel('Cumulative Profit (units)')\n",
    "    axes[0, 0].set_title('Cumulative P&L')\n",
    "    axes[0, 0].fill_between(range(len(cumulative_profit)), cumulative_profit, \n",
    "                            where=cumulative_profit >= 0, alpha=0.3, color='green')\n",
    "    axes[0, 0].fill_between(range(len(cumulative_profit)), cumulative_profit, \n",
    "                            where=cumulative_profit < 0, alpha=0.3, color='red')\n",
    "    \n",
    "    # CLV distribution\n",
    "    axes[0, 1].hist(results_df['clv'] * 100, bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].axvline(results_df['clv'].mean() * 100, color='red', linestyle='--', \n",
    "                       label=f'Mean: {results_df[\"clv\"].mean()*100:.2f}%')\n",
    "    axes[0, 1].set_xlabel('CLV (%)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Closing Line Value Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Calibration plot\n",
    "    prob_true, prob_pred = calibration_curve(results_df['won'], results_df['model_prob'], n_bins=8)\n",
    "    axes[1, 0].plot(prob_pred, prob_true, 's-', markersize=8, label='Model')\n",
    "    axes[1, 0].plot([0, 1], [0, 1], 'k--', label='Perfect')\n",
    "    axes[1, 0].set_xlabel('Predicted Probability')\n",
    "    axes[1, 0].set_ylabel('Actual Win Rate')\n",
    "    axes[1, 0].set_title('Model Calibration')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].set_xlim([0, 1])\n",
    "    axes[1, 0].set_ylim([0, 1])\n",
    "    \n",
    "    # ROI by market\n",
    "    market_roi = results_df.groupby('market').apply(\n",
    "        lambda x: x['profit'].sum() / x['stake'].sum() if x['stake'].sum() > 0 else 0\n",
    "    )\n",
    "    axes[1, 1].bar(market_roi.index, market_roi.values * 100, color='steelblue', edgecolor='black')\n",
    "    axes[1, 1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[1, 1].set_xlabel('Market')\n",
    "    axes[1, 1].set_ylabel('ROI (%)')\n",
    "    axes[1, 1].set_title('ROI by Market')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('backtest_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No bets to visualize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance testing\n",
    "def bootstrap_confidence_interval(profits, n_bootstrap=10000, confidence=0.95):\n",
    "    \"\"\"Calculate bootstrap CI for mean profit.\"\"\"\n",
    "    bootstrap_means = []\n",
    "    n = len(profits)\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(profits, size=n, replace=True)\n",
    "        bootstrap_means.append(np.mean(sample))\n",
    "    \n",
    "    lower = np.percentile(bootstrap_means, (1 - confidence) / 2 * 100)\n",
    "    upper = np.percentile(bootstrap_means, (1 + confidence) / 2 * 100)\n",
    "    \n",
    "    return lower, upper, np.mean(bootstrap_means)\n",
    "\n",
    "def permutation_test(profits, n_permutations=10000):\n",
    "    \"\"\"Test if mean profit is significantly different from zero.\"\"\"\n",
    "    observed_mean = np.mean(profits)\n",
    "    \n",
    "    # Under null hypothesis, randomly flip signs\n",
    "    count_extreme = 0\n",
    "    for _ in range(n_permutations):\n",
    "        signs = np.random.choice([-1, 1], size=len(profits))\n",
    "        permuted_mean = np.mean(profits * signs)\n",
    "        if permuted_mean >= observed_mean:\n",
    "            count_extreme += 1\n",
    "    \n",
    "    p_value = count_extreme / n_permutations\n",
    "    return p_value\n",
    "\n",
    "if len(results_df) > 30:\n",
    "    profits = results_df['profit'].values\n",
    "    \n",
    "    lower, upper, mean = bootstrap_confidence_interval(profits)\n",
    "    p_value = permutation_test(profits)\n",
    "    \n",
    "    print(\"\\n=== STATISTICAL SIGNIFICANCE ===\")\n",
    "    print(f\"Mean profit per bet: {mean:.4f} units\")\n",
    "    print(f\"95% CI: [{lower:.4f}, {upper:.4f}]\")\n",
    "    print(f\"Permutation test p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"Result: Statistically significant at α=0.05\")\n",
    "    else:\n",
    "        print(\"Result: NOT statistically significant at α=0.05\")\n",
    "    \n",
    "    print(f\"\\nNote: {len(results_df)} bets is {'sufficient' if len(results_df) > 500 else 'insufficient'} for reliable conclusions\")\n",
    "else:\n",
    "    print(\"Insufficient bets for significance testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Weekly Candidate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CandidateGenerator:\n",
    "    \"\"\"\n",
    "    Generate weekly betting candidates with full decision support.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, minutes_model, shot_model, config):\n",
    "        self.minutes_model = minutes_model\n",
    "        self.shot_model = shot_model\n",
    "        self.config = config\n",
    "    \n",
    "    def generate_candidates(self, player_df, odds_df):\n",
    "        \"\"\"\n",
    "        Generate candidate bets for upcoming matchweek.\n",
    "        \n",
    "        Args:\n",
    "            player_df: DataFrame with player features for upcoming matches\n",
    "            odds_df: DataFrame with current bookmaker odds\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame of betting candidates with recommendations\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        \n",
    "        # Merge player features with odds\n",
    "        merged = odds_df.merge(\n",
    "            player_df,\n",
    "            on=['player_id'],\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        for _, row in merged.iterrows():\n",
    "            if row['position'] == 'GK':\n",
    "                continue\n",
    "            \n",
    "            # Create single-row DataFrame for prediction\n",
    "            pred_df = merged[merged.index == row.name]\n",
    "            \n",
    "            # Minutes prediction\n",
    "            start_prob = self.minutes_model.predict_start_prob(pred_df)[0]\n",
    "            minutes_samples = self.minutes_model.sample_minutes(\n",
    "                np.array([start_prob]), n_samples=2000\n",
    "            )\n",
    "            expected_minutes = minutes_samples.mean()\n",
    "            \n",
    "            # Shot probabilities for different lines\n",
    "            for line in [0.5, 1.5, 2.5]:\n",
    "                model_prob_over = self.shot_model.predict_proba_over(\n",
    "                    pred_df, line=line, minutes_samples=minutes_samples\n",
    "                )[0]\n",
    "                \n",
    "                # Check if we have odds for this line\n",
    "                odds_key = f'shots_over_{line}'\n",
    "                if odds_key not in row.get('market', ''):\n",
    "                    continue\n",
    "                \n",
    "                # De-vig odds\n",
    "                devigged = OddsProcessor.devig_power(row['odds_over'], row['odds_under'])\n",
    "                \n",
    "                # Calculate EV\n",
    "                ev_over = OddsProcessor.calculate_ev(model_prob_over, row['odds_over'])\n",
    "                ev_under = OddsProcessor.calculate_ev(1 - model_prob_over, row['odds_under'])\n",
    "                \n",
    "                # Confidence interval on probability (simple approximation)\n",
    "                prob_std = np.sqrt(model_prob_over * (1 - model_prob_over) / 100)  # Approx\n",
    "                prob_lower = max(0, model_prob_over - 1.96 * prob_std)\n",
    "                prob_upper = min(1, model_prob_over + 1.96 * prob_std)\n",
    "                \n",
    "                # Determine recommendation\n",
    "                if ev_over > self.config['min_ev_threshold']:\n",
    "                    bet_side = 'OVER'\n",
    "                    bet_ev = ev_over\n",
    "                    bet_prob = model_prob_over\n",
    "                    bet_odds = row['odds_over']\n",
    "                    stake = OddsProcessor.kelly_stake(\n",
    "                        model_prob_over, row['odds_over'],\n",
    "                        self.config['kelly_fraction'],\n",
    "                        self.config['max_bet_fraction']\n",
    "                    )\n",
    "                elif ev_under > self.config['min_ev_threshold']:\n",
    "                    bet_side = 'UNDER'\n",
    "                    bet_ev = ev_under\n",
    "                    bet_prob = 1 - model_prob_over\n",
    "                    bet_odds = row['odds_under']\n",
    "                    stake = OddsProcessor.kelly_stake(\n",
    "                        1 - model_prob_over, row['odds_under'],\n",
    "                        self.config['kelly_fraction'],\n",
    "                        self.config['max_bet_fraction']\n",
    "                    )\n",
    "                else:\n",
    "                    continue  # No value\n",
    "                \n",
    "                # Risk notes\n",
    "                notes = []\n",
    "                if start_prob < 0.6:\n",
    "                    notes.append('ROTATION RISK')\n",
    "                if expected_minutes < 60:\n",
    "                    notes.append('LOW MINS')\n",
    "                if row.get('congestion', 0):\n",
    "                    notes.append('CONGESTION')\n",
    "                \n",
    "                candidates.append({\n",
    "                    'player_id': row['player_id'],\n",
    "                    'player_name': row.get('player_name', f'Player_{row[\"player_id\"]}'),\n",
    "                    'team': row.get('team', 'Unknown'),\n",
    "                    'opponent': row.get('opponent', 'Unknown'),\n",
    "                    'position': row['position'],\n",
    "                    'market': f'Shots {bet_side} {line}',\n",
    "                    'line': line,\n",
    "                    'bet_side': bet_side,\n",
    "                    'book_odds': bet_odds,\n",
    "                    'devig_market_prob': devigged['fair_prob_over'] if bet_side == 'OVER' else devigged['fair_prob_under'],\n",
    "                    'model_prob': bet_prob,\n",
    "                    'model_prob_lower': prob_lower if bet_side == 'OVER' else 1 - prob_upper,\n",
    "                    'model_prob_upper': prob_upper if bet_side == 'OVER' else 1 - prob_lower,\n",
    "                    'fair_odds': 1 / bet_prob,\n",
    "                    'ev_pct': bet_ev * 100,\n",
    "                    'stake_pct': stake * 100,\n",
    "                    'p_start': start_prob,\n",
    "                    'exp_minutes': expected_minutes,\n",
    "                    'notes': ', '.join(notes) if notes else '-'\n",
    "                })\n",
    "        \n",
    "        result_df = pd.DataFrame(candidates)\n",
    "        if len(result_df) > 0:\n",
    "            result_df = result_df.sort_values('ev_pct', ascending=False)\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "# Example: generate candidates for a matchweek\n",
    "print(\"Generating betting candidates...\")\n",
    "\n",
    "# Use recent data as \"upcoming\" matches\n",
    "upcoming_df = df[df['season'] == CONFIG['seasons'][-1]].tail(500).copy()\n",
    "upcoming_df = upcoming_df[upcoming_df['player_game_num'] >= 5]\n",
    "\n",
    "# Generate mock odds\n",
    "sample_odds = generate_synthetic_odds(\n",
    "    upcoming_df.sample(n=min(200, len(upcoming_df)), random_state=99),\n",
    "    shot_model, minutes_model\n",
    ")\n",
    "\n",
    "generator = CandidateGenerator(minutes_model, shot_model, CONFIG)\n",
    "candidates_df = generator.generate_candidates(upcoming_df, sample_odds)\n",
    "\n",
    "print(f\"\\nGenerated {len(candidates_df)} betting candidates\")\n",
    "if len(candidates_df) > 0:\n",
    "    print(\"\\n=== TOP 15 CANDIDATES ===\")\n",
    "    display_cols = ['player_name', 'team', 'opponent', 'market', 'book_odds', \n",
    "                    'model_prob', 'fair_odds', 'ev_pct', 'stake_pct', 'notes']\n",
    "    print(candidates_df[display_cols].head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export candidates to CSV\n",
    "if len(candidates_df) > 0:\n",
    "    export_df = candidates_df.round(4)\n",
    "    export_df.to_csv('betting_candidates.csv', index=False)\n",
    "    print(\"Candidates exported to betting_candidates.csv\")\n",
    "    \n",
    "    # Summary stats\n",
    "    print(f\"\\n=== CANDIDATE SUMMARY ===\")\n",
    "    print(f\"Total candidates: {len(candidates_df)}\")\n",
    "    print(f\"Average EV: {candidates_df['ev_pct'].mean():.2f}%\")\n",
    "    print(f\"Max EV: {candidates_df['ev_pct'].max():.2f}%\")\n",
    "    print(f\"Candidates with rotation risk: {(candidates_df['notes'].str.contains('ROTATION')).sum()}\")\n",
    "    print(f\"\\nBy market:\")\n",
    "    print(candidates_df.groupby('market').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Audit & Ablation Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ablation_study(df, odds_df, config):\n",
    "    \"\"\"\n",
    "    Test which model components contribute to edge.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # 1. Full model\n",
    "    print(\"Testing: Full model...\")\n",
    "    full_minutes = MinutesModel()\n",
    "    full_minutes.fit(df)\n",
    "    full_shots = HierarchicalShotModel()\n",
    "    full_shots.fit(df)\n",
    "    \n",
    "    backtester = Backtester(config)\n",
    "    full_results = backtester.run_backtest(df, odds_df, full_minutes, full_shots)\n",
    "    results['Full Model'] = backtester.summarize_results(full_results)\n",
    "    \n",
    "    # 2. Without minutes uncertainty (use point estimate)\n",
    "    print(\"Testing: Without minutes uncertainty...\")\n",
    "    \n",
    "    class FixedMinutesModel(MinutesModel):\n",
    "        def sample_minutes(self, start_probs, n_samples=1000):\n",
    "            # Return fixed expected minutes instead of distribution\n",
    "            n_players = len(start_probs)\n",
    "            samples = np.zeros((n_players, n_samples))\n",
    "            for i, p_start in enumerate(start_probs):\n",
    "                expected = p_start * self.starter_mu + (1 - p_start) * self.sub_mu * 0.5\n",
    "                samples[i] = expected  # No variation\n",
    "            return samples\n",
    "    \n",
    "    fixed_minutes = FixedMinutesModel()\n",
    "    fixed_minutes.fit(df)\n",
    "    fixed_results = backtester.run_backtest(df, odds_df, fixed_minutes, full_shots)\n",
    "    results['No Minutes Uncertainty'] = backtester.summarize_results(fixed_results)\n",
    "    \n",
    "    # 3. Without player effects\n",
    "    print(\"Testing: Without player effects...\")\n",
    "    \n",
    "    class NoPlayerEffectsModel(HierarchicalShotModel):\n",
    "        def fit(self, df):\n",
    "            super().fit(df)\n",
    "            self.player_effects = {}  # Remove player effects\n",
    "            return self\n",
    "    \n",
    "    no_player = NoPlayerEffectsModel()\n",
    "    no_player.fit(df)\n",
    "    no_player_results = backtester.run_backtest(df, odds_df, full_minutes, no_player)\n",
    "    results['No Player Effects'] = backtester.summarize_results(no_player_results)\n",
    "    \n",
    "    # 4. Without opponent effects\n",
    "    print(\"Testing: Without opponent effects...\")\n",
    "    \n",
    "    class NoOpponentEffectsModel(HierarchicalShotModel):\n",
    "        def fit(self, df):\n",
    "            super().fit(df)\n",
    "            self.opponent_effects = {}  # Remove opponent effects\n",
    "            return self\n",
    "    \n",
    "    no_opp = NoOpponentEffectsModel()\n",
    "    no_opp.fit(df)\n",
    "    no_opp_results = backtester.run_backtest(df, odds_df, full_minutes, no_opp)\n",
    "    results['No Opponent Effects'] = backtester.summarize_results(no_opp_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run ablation study\n",
    "print(\"\\n=== ABLATION STUDY ===\")\n",
    "ablation_results = run_ablation_study(df, odds_df, CONFIG)\n",
    "\n",
    "print(\"\\n=== RESULTS COMPARISON ===\")\n",
    "comparison_df = pd.DataFrame(ablation_results).T\n",
    "print(comparison_df[['n_bets', 'roi', 'avg_clv', 'win_rate']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusions & Next Steps\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Minutes uncertainty matters**: The two-stage minutes model captures rotation/substitution risk that sportsbooks often misprice.\n",
    "\n",
    "2. **Hierarchical effects help**: Player and opponent random effects improve calibration by pooling information.\n",
    "\n",
    "3. **CLV is the key metric**: Focus on beating the market's closing price, not raw ROI.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "- Synthetic data used for demonstration; real edge requires real odds\n",
    "- Player props have low betting limits; scaling is constrained\n",
    "- Model assumes stable player roles and team tactics\n",
    "- Injury/lineup information not incorporated\n",
    "\n",
    "### Next Steps for Production\n",
    "\n",
    "1. Connect to live odds feeds (OddsAPI, sportsbook APIs)\n",
    "2. Implement closing line tracking for true CLV measurement\n",
    "3. Add injury/news integration\n",
    "4. Expand to SOT-specific model with tighter priors\n",
    "5. Consider PyMC for full Bayesian inference with uncertainty\n",
    "6. Build automated weekly pipeline\n",
    "\n",
    "### Risk Management Reminders\n",
    "\n",
    "- Never risk more than you can afford to lose\n",
    "- Use fractional Kelly (0.25) to reduce variance\n",
    "- Track results meticulously\n",
    "- Be patient: 1000+ bets needed for statistical confidence\n",
    "- Follow local laws and sportsbook terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model version info for audit log\n",
    "import datetime\n",
    "\n",
    "audit_log = {\n",
    "    'model_version': '1.0.0',\n",
    "    'created_at': datetime.datetime.now().isoformat(),\n",
    "    'training_seasons': train_seasons,\n",
    "    'n_training_records': len(train_df),\n",
    "    'config': CONFIG,\n",
    "    'minutes_model_auc': start_auc,\n",
    "    'shot_model_mae': mae,\n",
    "    'backtest_n_bets': summary.get('n_bets', 0),\n",
    "    'backtest_roi': summary.get('roi', 0),\n",
    "    'backtest_clv': summary.get('avg_clv', 0)\n",
    "}\n",
    "\n",
    "print(\"=== AUDIT LOG ===\")\n",
    "for key, value in audit_log.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Save audit log\n",
    "import json\n",
    "with open('model_audit_log.json', 'w') as f:\n",
    "    json.dump(audit_log, f, indent=2, default=str)\n",
    "print(\"\\nAudit log saved to model_audit_log.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for loading real bookmaker odds\n",
    "\"\"\"\n",
    "ODDS CSV FORMAT:\n",
    "\n",
    "match_id,player_id,player_name,team,opponent,date,market,line,odds_over,odds_under,book,timestamp\n",
    "12345,67890,Mohamed Salah,Liverpool,Arsenal,2024-02-10,shots,1.5,1.85,1.95,DraftKings,2024-02-10T09:00:00\n",
    "12345,67890,Mohamed Salah,Liverpool,Arsenal,2024-02-10,shots,2.5,2.50,1.52,DraftKings,2024-02-10T09:00:00\n",
    "\n",
    "def load_odds_csv(filepath):\n",
    "    odds_df = pd.read_csv(filepath, parse_dates=['date', 'timestamp'])\n",
    "    \n",
    "    # Validate required columns\n",
    "    required = ['player_id', 'market', 'line', 'odds_over', 'odds_under']\n",
    "    assert all(col in odds_df.columns for col in required)\n",
    "    \n",
    "    # Filter stale odds (>24 hours old)\n",
    "    now = pd.Timestamp.now()\n",
    "    odds_df = odds_df[odds_df['timestamp'] > now - pd.Timedelta(hours=24)]\n",
    "    \n",
    "    return odds_df\n",
    "\n",
    "# Load and process\n",
    "# real_odds = load_odds_csv('weekly_odds.csv')\n",
    "# candidates = generator.generate_candidates(upcoming_features, real_odds)\n",
    "\"\"\"\n",
    "print(\"Real odds loading template defined (see cell above)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
